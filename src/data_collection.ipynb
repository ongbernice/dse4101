{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of US Tech Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the Stock Analysis screener URL\n",
    "url = \"https://stockanalysis.com/stocks/sector/technology/\"\n",
    "\n",
    "# Fetch the webpage content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Locate the table in the screener\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Extract headers\n",
    "headers = [header.text for header in table.find_all(\"th\")]\n",
    "\n",
    "# Extract rows\n",
    "rows = []\n",
    "for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "    cols = [col.text.strip() for col in row.find_all(\"td\")]\n",
    "    rows.append(cols)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "# drop first column\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "# rename columns\n",
    "df.columns = ['Symbol', 'Company', 'Market Cap', '% Change', 'Volume', 'Revenue']\n",
    "df = df.dropna()\n",
    "# save to csv\n",
    "df.to_csv('../data/us_tech_stocks_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Prices from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# List of US tech stock tickers\n",
    "tech_stocks = pd.read_csv('../data/us_tech_stocks_list.csv', na_filter=False)['Symbol'].tolist()\n",
    "\n",
    "# Define the time horizon\n",
    "start_date = '1999-01-01'\n",
    "end_date = '2025-01-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch monthly historical stock prices and compute monthly returns\n",
    "def fetch_monthly_stock_data(ticker, start_date, end_date):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    hist_data = stock.history(start=start_date, end=end_date, interval='1mo')  # Fetch monthly data\n",
    "    hist_data['Ticker'] = ticker\n",
    "    hist_data['Monthly_Return'] = hist_data['Close'].pct_change() # Compute monthly returns\n",
    "    return hist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical data for US Tech Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect monthly data for all stocks\n",
    "all_data = []\n",
    "for ticker in tech_stocks:\n",
    "    print(f\"Fetching monthly data for {ticker}...\")\n",
    "    stock_data = fetch_monthly_stock_data(ticker, start_date, end_date)\n",
    "    all_data.append(stock_data)\n",
    "\n",
    "# Combine all monthly stock data\n",
    "combined_data = pd.concat(all_data)\n",
    "\n",
    "print(\"Monthly stock data collection complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Adj Close column\n",
    "combined_data.drop(columns=['Adj Close'], inplace=True)\n",
    "# drop rows with missing values\n",
    "combined_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "combined_data.to_csv('../data/monthly_tech_stocks_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical data for XLK Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLK returns data collection complete!\n"
     ]
    }
   ],
   "source": [
    "# Fetch historical data for XLK\n",
    "xlk_data = fetch_monthly_stock_data('XLK', start_date, end_date)\n",
    "# drop missing values\n",
    "xlk_data.dropna(inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "xlk_data.to_csv('../data/xlk_returns.csv', index=True)\n",
    "\n",
    "print(\"XLK returns data collection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro Indicators from FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fredapi import Fred\n",
    "import os\n",
    "\n",
    "# Retrieve the FRED API key from the environment variable\n",
    "fred = Fred(api_key=os.getenv('FRED_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 3_Month_Treasury_Bill_Yield (TB3MS)...\n",
      "Fetching 6_Month_Treasury_Bill_Yield (TB6MS)...\n",
      "Fetching 1_Year_Treasury_Bill_Yield (GS1)...\n",
      "Fetching AAA_Bond_Yield (AAA)...\n",
      "Fetching BAA_Bond_Yield (BAA)...\n",
      "Fetching Oil_Price_WTI (DCOILWTICO)...\n",
      "Fetching Inflation_CPI (CPIAUCSL)...\n",
      "Fetching Federal_Funds_Rate (FEDFUNDS)...\n",
      "Fetching Unemployment_Rate (UNRATE)...\n"
     ]
    }
   ],
   "source": [
    "# Define the macroeconomic indicators with their FRED codes\n",
    "indicators = {\n",
    "    \"3_Month_Treasury_Bill_Yield\": \"TB3MS\",\n",
    "    \"6_Month_Treasury_Bill_Yield\": \"TB6MS\",\n",
    "    \"1_Year_Treasury_Bill_Yield\": \"GS1\",\n",
    "    \"AAA_Bond_Yield\": \"AAA\",\n",
    "    \"BAA_Bond_Yield\": \"BAA\",\n",
    "    \"Oil_Price_WTI\": \"DCOILWTICO\",\n",
    "    \"Inflation_CPI\": \"CPIAUCSL\",\n",
    "    \"Federal_Funds_Rate\": \"FEDFUNDS\",\n",
    "    \"Unemployment_Rate\": \"UNRATE\"\n",
    "}\n",
    "\n",
    "# Fetch data for all indicators\n",
    "data = {}\n",
    "for name, code in indicators.items():\n",
    "    print(f\"Fetching {name} ({code})...\")\n",
    "    try:\n",
    "        # Fetch data from FRED\n",
    "        series = fred.get_series(code)\n",
    "        data[name] = series\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch {name}: {e}\")\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "macro_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to the first day of each month\n",
    "macro_df = macro_df.resample('MS').mean()\n",
    "\n",
    "# Convert relevant columns to decimals (e.g., percentage values)\n",
    "columns_to_convert = [\n",
    "    \"3_Month_Treasury_Bill_Yield\",\n",
    "    \"6_Month_Treasury_Bill_Yield\",\n",
    "    \"1_Year_Treasury_Bill_Yield\",\n",
    "    \"AAA_Bond_Yield\",\n",
    "    \"BAA_Bond_Yield\",\n",
    "    \"Federal_Funds_Rate\",\n",
    "    \"Unemployment_Rate\"\n",
    "]\n",
    "\n",
    "# Convert percentage columns to decimal format\n",
    "macro_df[columns_to_convert] = macro_df[columns_to_convert] / 100\n",
    "\n",
    "# Calculate Inflation Rate as the monthly percentage change in CPI\n",
    "macro_df[\"Inflation_Rate\"] = macro_df[\"Inflation_CPI\"].pct_change()  # Get relative change\n",
    "# Drop the original CPI column if no longer needed\n",
    "macro_df.drop(columns=[\"Inflation_CPI\"], inplace=True)\n",
    "\n",
    "# calculate oil price change\n",
    "macro_df['Oil_Price_WTI_change'] = macro_df['Oil_Price_WTI'].pct_change()\n",
    "# drop oil price column\n",
    "macro_df.drop(columns=['Oil_Price_WTI'], inplace=True)\n",
    "\n",
    "# filter start and end date\n",
    "macro_df = macro_df.loc[start_date:end_date]\n",
    "\n",
    "print(macro_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse date to datetime\n",
    "macro_df.index = pd.to_datetime(macro_df.index)\n",
    "# Save to CSV\n",
    "macro_df.to_csv(\"../data/macro_indicators.csv\", index=True, index_label='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stocks data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Stocks data with Macro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the stock data\n",
    "stock_data = pd.read_csv('../data/monthly_tech_stocks_data.csv')\n",
    "# slice string from date\n",
    "stock_data['Date'] = stock_data['Date'].str.slice(0,10)\n",
    "# convert date to datetime\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "stock_data.sort_values(by=['Ticker', 'Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 313 entries, 0 to 312\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   Date                         313 non-null    datetime64[ns]\n",
      " 1   3_Month_Treasury_Bill_Yield  312 non-null    float64       \n",
      " 2   6_Month_Treasury_Bill_Yield  312 non-null    float64       \n",
      " 3   1_Year_Treasury_Bill_Yield   312 non-null    float64       \n",
      " 4   AAA_Bond_Yield               312 non-null    float64       \n",
      " 5   BAA_Bond_Yield               312 non-null    float64       \n",
      " 6   Federal_Funds_Rate           312 non-null    float64       \n",
      " 7   Unemployment_Rate            312 non-null    float64       \n",
      " 8   Inflation_Rate               313 non-null    float64       \n",
      " 9   Oil_Price_WTI_change         313 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(9)\n",
      "memory usage: 24.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Load macroeconomic data\n",
    "macro_data = pd.read_csv(\"../data/macro_indicators.csv\", parse_dates=['Date'])\n",
    "macro_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stock data with macroeconomic data\n",
    "combined_df = pd.merge(stock_data, macro_data, on='Date', how='left')\n",
    "\n",
    "# Handle missing values\n",
    "combined_df.ffill(inplace=True)  # Forward-fill missing macroeconomic data\n",
    "combined_df.dropna(inplace=True)  # Drop rows with remaining missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def add_features(df):\n",
    "    # Rolling 3-month moving average of returns\n",
    "    df['Rolling_Return_3M'] = df.groupby('Ticker')['Monthly_Return'].rolling(window=3).mean().reset_index(0, drop=True)\n",
    "    \n",
    "    # Rolling volatility (standard deviation) of returns over 3 months\n",
    "    df['Rolling_Volatility_3M'] = df.groupby('Ticker')['Monthly_Return'].rolling(window=3).std().reset_index(0, drop=True)\n",
    "\n",
    "    # Compute risk premium\n",
    "    df['Risk_Premium'] = df['Monthly_Return'] - df['3_Month_Treasury_Bill_Yield']\n",
    "\n",
    "    # Lagged risk premium (1-month lag)\n",
    "    df['Lagged_Risk_Premium'] = df.groupby('Ticker')['Risk_Premium'].shift(1)\n",
    "    \n",
    "    # Drop rows with NaN values caused by rolling calculations\n",
    "    df.dropna(subset=['Lagged_Risk_Premium', 'Rolling_Return_3M', 'Rolling_Volatility_3M'], inplace=True)\n",
    "    return df\n",
    "\n",
    "final_combined_df = add_features(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "final_combined_df.to_csv('../data/final_tech_stock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLK data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlk_data = pd.read_csv('../data/xlk_returns.csv')\n",
    "# slice string from date\n",
    "xlk_data['Date'] = xlk_data['Date'].str.slice(0,10)\n",
    "# convert date to datetime\n",
    "xlk_data['Date'] = pd.to_datetime(xlk_data['Date'])\n",
    "\n",
    "# merge with macro data\n",
    "xlk_data = pd.merge(xlk_data, macro_data, on='Date', how='left')\n",
    "# compute risk premium\n",
    "xlk_data['Risk_Premium'] = xlk_data['Monthly_Return'] - xlk_data['3_Month_Treasury_Bill_Yield']\n",
    "# keep only relevant columns\n",
    "xlk_data = xlk_data[['Date', '3_Month_Treasury_Bill_Yield', 'Monthly_Return', 'Risk_Premium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "xlk_data.to_csv('../data/final_xlk_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
